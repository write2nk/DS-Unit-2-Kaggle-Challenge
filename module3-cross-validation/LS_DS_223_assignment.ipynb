{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "LS_DS_223_assignment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlNBz5Zrnhsv"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 3*\n",
        "\n",
        "---\n",
        "<p style=\"padding: 10px; border: 2px solid red;\">\n",
        "    <b>Before you start:</b> Today is the day you should submit the dataset for your Unit 2 Build Week project. You can review the guidelines and make your submission in the Build Week course for your cohort on Canvas.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiB6IqUOnhsy"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/main/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install pandas-profiling==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buUISqU7nhsz"
      },
      "source": [
        "# Module Project: Hyperparameter Tuning\n",
        "\n",
        "This sprint, the module projects will focus on creating and improving a model for the Tanazania Water Pump dataset. Your goal is to create a model to predict whether a water pump is functional, non-functional, or needs repair.\n",
        "\n",
        "Dataset source: [DrivenData.org](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are as follows:\n",
        "\n",
        "- **Task 1:** Use `wrangle` function to import training and test data.\n",
        "- **Task 2:** Split training data into feature matrix `X` and target vector `y`.\n",
        "- **Task 3:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 4:** Build `clf_dt`.\n",
        "- **Task 5:** Build `clf_rf`.\n",
        "- **Task 6:** Evaluate classifiers using k-fold cross-validation.\n",
        "- **Task 7:** Tune hyperparameters for best performing classifier.\n",
        "- **Task 8:** Print out best score and params for model.\n",
        "- **Task 9:** Create `submission.csv` and upload to Kaggle.\n",
        "\n",
        "You should limit yourself to the following libraries for this project:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `pandas-profiling`\n",
        "- `sklearn`\n",
        "\n",
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96fkwQgTnhs0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv')).set_index('id')\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv').set_index('id')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "# Split train into train & val\n",
        "#train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              #stratify=train['status_group'], random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqrRpDZZpReI"
      },
      "source": [
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd2rJtqgpgmR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZvlngPknhs1"
      },
      "source": [
        "**Task 1:** Using the above `wrangle` function to read `train_features.csv` and `train_labels.csv` into the DataFrame `df`, and `test_features.csv` into the DataFrame `X_test`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOSuUk6onhs2"
      },
      "source": [
        "df = wrangle(train)\n",
        "X_test = wrangle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2GhlkOXnhs3"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 2:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'status_group'`.\n",
        "\n",
        "**Note:** You won't need to do a train-test split because you'll use cross-validation instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BgGf3aVnhs6"
      },
      "source": [
        "target = 'status_group'\n",
        "y = df[target]\n",
        "X = df.drop(columns=target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7ygbS0tm0cl"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzvK9Xufnhs7"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 3:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBz7LvcPnhs8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed4ee11-6d16-41cd-bbcf-f9915eda693d"
      },
      "source": [
        "baseline_acc = y.value_counts(normalize = True)\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy Score: functional                 0.543081\n",
            "non functional             0.384242\n",
            "functional needs repair    0.072677\n",
            "Name: status_group, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHcJkHtwnhs9"
      },
      "source": [
        "# IV. Build Models\n",
        "\n",
        "**Task 4:** Build a `Pipeline` named `clf_dt`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `DecisionTreeClassifier` Predictor.\n",
        "\n",
        "**Note:** Do not train `clf_dt`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpq5PUoEnhs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb12ac3-d0c8-472f-807b-466175061900"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf_dt = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median', verbose=0),\n",
        "    DecisionTreeClassifier(random_state=42, max_depth=None,),\n",
        ")\n",
        "sorted(clf_dt.get_params().keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['decisiontreeclassifier',\n",
              " 'decisiontreeclassifier__ccp_alpha',\n",
              " 'decisiontreeclassifier__class_weight',\n",
              " 'decisiontreeclassifier__criterion',\n",
              " 'decisiontreeclassifier__max_depth',\n",
              " 'decisiontreeclassifier__max_features',\n",
              " 'decisiontreeclassifier__max_leaf_nodes',\n",
              " 'decisiontreeclassifier__min_impurity_decrease',\n",
              " 'decisiontreeclassifier__min_impurity_split',\n",
              " 'decisiontreeclassifier__min_samples_leaf',\n",
              " 'decisiontreeclassifier__min_samples_split',\n",
              " 'decisiontreeclassifier__min_weight_fraction_leaf',\n",
              " 'decisiontreeclassifier__presort',\n",
              " 'decisiontreeclassifier__random_state',\n",
              " 'decisiontreeclassifier__splitter',\n",
              " 'memory',\n",
              " 'ordinalencoder',\n",
              " 'ordinalencoder__cols',\n",
              " 'ordinalencoder__drop_invariant',\n",
              " 'ordinalencoder__handle_missing',\n",
              " 'ordinalencoder__handle_unknown',\n",
              " 'ordinalencoder__mapping',\n",
              " 'ordinalencoder__return_df',\n",
              " 'ordinalencoder__verbose',\n",
              " 'simpleimputer',\n",
              " 'simpleimputer__add_indicator',\n",
              " 'simpleimputer__copy',\n",
              " 'simpleimputer__fill_value',\n",
              " 'simpleimputer__missing_values',\n",
              " 'simpleimputer__strategy',\n",
              " 'simpleimputer__verbose',\n",
              " 'steps',\n",
              " 'verbose']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIw5xiHKnhs-"
      },
      "source": [
        "**Task 5:** Build a `Pipeline` named `clf_rf`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `RandomForestClassifier` predictor.\n",
        "\n",
        "**Note:** Do not train `clf_rf`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPAb6cP2nhs_"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf_rf =  make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwc8rg_u---v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7Hezi_Ynhs_"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "**Task 6:** Evaluate the performance of both of your classifiers using k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bhlWl8TnhtA"
      },
      "source": [
        "from sklearn.model_selection import KFold,  cross_val_score\n",
        "k = 5\n",
        "cv_scores_dt = cross_val_score(clf_dt, X, y, cv = k)\n",
        "cv_scores_rf = cross_val_score(clf_rf, X, y, cv = k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfVDhSqhnhtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7cb5c87-c58e-474c-fc3e-fc6b307620e9"
      },
      "source": [
        "print('CV scores DecisionTreeClassifier')\n",
        "print(cv_scores_dt)\n",
        "print('Mean CV accuracy score:', cv_scores_dt.mean())\n",
        "print('STD CV accuracy score:', cv_scores_dt.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV scores DecisionTreeClassifier\n",
            "[0.69646465 0.71136364 0.71624579 0.70530303 0.71287879]\n",
            "Mean CV accuracy score: 0.7084511784511784\n",
            "STD CV accuracy score: 0.006963187643315079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN37kpYznhtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ca54e9-d971-4b84-ba76-1525ffba66d4"
      },
      "source": [
        "print('CV score RandomForestClassifier')\n",
        "print(cv_scores_rf)\n",
        "print('Mean CV accuracy score:', cv_scores_rf.mean())\n",
        "print('STD CV accuracy score:', cv_scores_rf.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score RandomForestClassifier\n",
            "[0.81228956 0.80698653 0.80934343 0.80833333 0.80841751]\n",
            "Mean CV accuracy score: 0.8090740740740741\n",
            "STD CV accuracy score: 0.0017747972668610615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLdj9V48nhtB"
      },
      "source": [
        "# VI. Tune Model\n",
        "\n",
        "**Task 7:** Choose the best performing of your two models and tune its hyperparameters using a `RandomizedSearchCV` named `model`. Make sure that you include cross-validation and that `n_iter` is set to at least `25`.\n",
        "\n",
        "**Note:** If you're not sure which hyperparameters to tune, check the notes from today's guided project and the `sklearn` documentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m49R6BzG_1MG"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STwGeBbQF8DT"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('encoder', OrdinalEncoder()),\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('classifier', DecisionTreeClassifier(random_state = 42))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPO4gryhnhtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69a4625-1e26-4c5a-96ea-989352874090"
      },
      "source": [
        "from scipy.stats import randint\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "features = df.columns.drop([target])\n",
        "X_train = df[features]\n",
        "y_train = df[target]\n",
        "\n",
        "# Setup the parameters and distributions to sample from: param_dist\n",
        "param_dist = {\"classifier__max_depth\": [3, None],\n",
        "              'imputer__strategy': ['mean', 'median'],\n",
        "              \"classifier__max_features\": randint(1, 9),\n",
        "              \"classifier__min_samples_leaf\": randint(1, 9),\n",
        "              \"classifier__criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "# Instantiate a Decision Tree classifier: tree\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# Instantiate the RandomizedSearchCV object: tree_cv\n",
        "#tree_cv = RandomizedSearchCV(tree, param_dist, n_iter=25,  cv=5)\n",
        "tree_cv = RandomizedSearchCV(\n",
        "    pipeline, \n",
        "    param_distributions=param_dist, \n",
        "    n_iter=25, \n",
        "    cv=3,    \n",
        ")\n",
        "\n",
        "tree_cv.fit(X_train, y_train)\n",
        " #If you're on Colab, decrease n_iter & cv parameters\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=Pipeline(memory=None,\n",
              "                                      steps=[('encoder',\n",
              "                                              OrdinalEncoder(cols=None,\n",
              "                                                             drop_invariant=False,\n",
              "                                                             handle_missing='value',\n",
              "                                                             handle_unknown='value',\n",
              "                                                             mapping=None,\n",
              "                                                             return_df=True,\n",
              "                                                             verbose=0)),\n",
              "                                             ('imputer',\n",
              "                                              SimpleImputer(add_indicator=False,\n",
              "                                                            copy=True,\n",
              "                                                            fill_value=None,\n",
              "                                                            missing_values=nan,\n",
              "                                                            strategy='median',\n",
              "                                                            verbose=0)),\n",
              "                                             ('classif...\n",
              "                                        'classifier__max_depth': [3, None],\n",
              "                                        'classifier__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f817aace9d0>,\n",
              "                                        'classifier__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f817aacef50>,\n",
              "                                        'imputer__strategy': ['mean',\n",
              "                                                              'median']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ImpBL5Hbok5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdFGPt7Z7gKX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoDi9D0wQRdo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qofhTq-D2dD0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFO48BZ-nhtB"
      },
      "source": [
        "**Task 8:** Print out the best score and best params for `model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rf_cw75nhtC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5450fd1b-ae5f-4386-ce4d-63599c9c30cc"
      },
      "source": [
        "best_score = tree_cv.best_score_\n",
        "best_params = tree_cv.best_params_\n",
        "\n",
        "print('Best score for `model`:', best_score)\n",
        "print('Best params for `model`:', best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score for `model`: 0.7528114478114478\n",
            "Best params for `model`: {'classifier__criterion': 'entropy', 'classifier__max_depth': None, 'classifier__max_features': 7, 'classifier__min_samples_leaf': 6, 'imputer__strategy': 'mean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGhr1OQKnhtC"
      },
      "source": [
        "# Communicate Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG3tnI7mnhtC"
      },
      "source": [
        "**Task 9:** Create a DataFrame `submission` whose index is the same as `X_test` and that has one column `'status_group'` with your predictions. Next, save this DataFrame as a CSV file and upload your submissions to our competition site. \n",
        "\n",
        "**Note:** Check the `sample_submission.csv` file on the competition website to make sure your submissions follows the same formatting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxPoO3r3NlSe",
        "outputId": "561dc04b-0aaf-431c-e6be-362f0f772035"
      },
      "source": [
        "#since we have found the best parameters, we plug them in and then fit and make prediction\n",
        "best_model = Pipeline([\n",
        "    ('encoder', OrdinalEncoder()),\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('classifier', DecisionTreeClassifier(criterion = 'gini', max_depth = None, max_features = 8, min_samples_leaf = 7,\n",
        "                                          random_state = 42))\n",
        "])\n",
        "\n",
        "best_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('encoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'installer', 'wpt_name',\n",
              "                                      'basin', 'subvillage', 'region', 'lga',\n",
              "                                      'ward', 'public_meeting',\n",
              "                                      'scheme_management', 'scheme_name',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'management_group', 'payment',\n",
              "                                      'water_quality', 'quality_group',\n",
              "                                      'quantity', 'sou...\n",
              "                               missing_values=nan, strategy='mean',\n",
              "                               verbose=0)),\n",
              "                ('classifier',\n",
              "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                        criterion='gini', max_depth=None,\n",
              "                                        max_features=8, max_leaf_nodes=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=7, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        presort='deprecated', random_state=42,\n",
              "                                        splitter='best'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "IYaCQN4dSDbe",
        "outputId": "72a40dab-129f-4101-f911-e34e194890d8"
      },
      "source": [
        "print('X_test', X_test.shape)\n",
        "print('X_train', X_train.shape)\n",
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test (14358, 45)\n",
            "X_train (59400, 45)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount_tsh</th>\n",
              "      <th>funder</th>\n",
              "      <th>gps_height</th>\n",
              "      <th>installer</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>wpt_name</th>\n",
              "      <th>num_private</th>\n",
              "      <th>basin</th>\n",
              "      <th>subvillage</th>\n",
              "      <th>region</th>\n",
              "      <th>region_code</th>\n",
              "      <th>district_code</th>\n",
              "      <th>lga</th>\n",
              "      <th>ward</th>\n",
              "      <th>population</th>\n",
              "      <th>public_meeting</th>\n",
              "      <th>scheme_management</th>\n",
              "      <th>scheme_name</th>\n",
              "      <th>permit</th>\n",
              "      <th>construction_year</th>\n",
              "      <th>extraction_type</th>\n",
              "      <th>extraction_type_group</th>\n",
              "      <th>extraction_type_class</th>\n",
              "      <th>management</th>\n",
              "      <th>management_group</th>\n",
              "      <th>payment</th>\n",
              "      <th>water_quality</th>\n",
              "      <th>quality_group</th>\n",
              "      <th>quantity</th>\n",
              "      <th>source</th>\n",
              "      <th>source_type</th>\n",
              "      <th>source_class</th>\n",
              "      <th>waterpoint_type</th>\n",
              "      <th>waterpoint_type_group</th>\n",
              "      <th>longitude_MISSING</th>\n",
              "      <th>latitude_MISSING</th>\n",
              "      <th>construction_year_MISSING</th>\n",
              "      <th>gps_height_MISSING</th>\n",
              "      <th>population_MISSING</th>\n",
              "      <th>year_recorded</th>\n",
              "      <th>month_recorded</th>\n",
              "      <th>day_recorded</th>\n",
              "      <th>years</th>\n",
              "      <th>years_MISSING</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50785</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Dmdd</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>DMDD</td>\n",
              "      <td>35.290799</td>\n",
              "      <td>-4.059696</td>\n",
              "      <td>Dinamu Secondary School</td>\n",
              "      <td>0</td>\n",
              "      <td>Internal</td>\n",
              "      <td>Magoma</td>\n",
              "      <td>Manyara</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>Mbulu</td>\n",
              "      <td>Bashay</td>\n",
              "      <td>321.0</td>\n",
              "      <td>True</td>\n",
              "      <td>Parastatal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>parastatal</td>\n",
              "      <td>parastatal</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>seasonal</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51630</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Government Of Tanzania</td>\n",
              "      <td>1569.0</td>\n",
              "      <td>DWE</td>\n",
              "      <td>36.656709</td>\n",
              "      <td>-3.309214</td>\n",
              "      <td>Kimnyak</td>\n",
              "      <td>0</td>\n",
              "      <td>Pangani</td>\n",
              "      <td>Kimnyak</td>\n",
              "      <td>Arusha</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Arusha Rural</td>\n",
              "      <td>Kimnyaki</td>\n",
              "      <td>300.0</td>\n",
              "      <td>True</td>\n",
              "      <td>VWC</td>\n",
              "      <td>TPRI pipe line</td>\n",
              "      <td>True</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>spring</td>\n",
              "      <td>spring</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>13.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17168</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1567.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.767863</td>\n",
              "      <td>-5.004344</td>\n",
              "      <td>Puma Secondary</td>\n",
              "      <td>0</td>\n",
              "      <td>Internal</td>\n",
              "      <td>Msatu</td>\n",
              "      <td>Singida</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>Singida Rural</td>\n",
              "      <td>Puma</td>\n",
              "      <td>500.0</td>\n",
              "      <td>True</td>\n",
              "      <td>VWC</td>\n",
              "      <td>P</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45559</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Finn Water</td>\n",
              "      <td>267.0</td>\n",
              "      <td>FINN WATER</td>\n",
              "      <td>38.058046</td>\n",
              "      <td>-9.418672</td>\n",
              "      <td>Kwa Mzee Pange</td>\n",
              "      <td>0</td>\n",
              "      <td>Ruvuma / Southern Coast</td>\n",
              "      <td>Kipindimbi</td>\n",
              "      <td>Lindi</td>\n",
              "      <td>80</td>\n",
              "      <td>43</td>\n",
              "      <td>Liwale</td>\n",
              "      <td>Mkutano</td>\n",
              "      <td>250.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VWC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>1987.0</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>unknown</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>dry</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>26.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49871</th>\n",
              "      <td>500.0</td>\n",
              "      <td>Bruder</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>BRUDER</td>\n",
              "      <td>35.006123</td>\n",
              "      <td>-10.950412</td>\n",
              "      <td>Kwa Mzee Turuka</td>\n",
              "      <td>0</td>\n",
              "      <td>Ruvuma / Southern Coast</td>\n",
              "      <td>Losonga</td>\n",
              "      <td>Ruvuma</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>Mbinga</td>\n",
              "      <td>Mbinga Urban</td>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Water Board</td>\n",
              "      <td>BRUDER</td>\n",
              "      <td>True</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>water board</td>\n",
              "      <td>user-group</td>\n",
              "      <td>pay monthly</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>spring</td>\n",
              "      <td>spring</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2013</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>13.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       amount_tsh                  funder  ...  years years_MISSING\n",
              "id                                         ...                     \n",
              "50785         0.0                    Dmdd  ...    1.0         False\n",
              "51630         0.0  Government Of Tanzania  ...   13.0         False\n",
              "17168         0.0                     NaN  ...    3.0         False\n",
              "45559         0.0              Finn Water  ...   26.0         False\n",
              "49871       500.0                  Bruder  ...   13.0         False\n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3nmuSzHLeAR"
      },
      "source": [
        "#make predictions first\n",
        "pred = best_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMES9SignhtC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "ea46e0af-bd1e-4b70-cd8c-ddb08cdb95e3"
      },
      "source": [
        "#Create a datafram submission\n",
        "submission = submission = pd.DataFrame(pred, columns = ['Status_group'], index = X_test.index)\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Status_group</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50785</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51630</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17168</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45559</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49871</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Status_group\n",
              "id                   \n",
              "50785  non functional\n",
              "51630  non functional\n",
              "17168      functional\n",
              "45559  non functional\n",
              "49871      functional"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGU3Ju_jTb1g"
      },
      "source": [
        "#Save into a csv file for upload\n",
        "submission.to_csv('Tanzania_water_pred_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}